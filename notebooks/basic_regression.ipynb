{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9dea388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from datetime import date, timedelta\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import rowcol\n",
    "from pyproj import Transformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "\n",
    "FWI_DIR   = \"fwi/fwi_tifs_2025_09_12_2025_10_10/\"\n",
    "ECMWF_DIR = \"ecmwf/ecmwf_on_fwi_grid/\"\n",
    "CIFFC_FILE = \"ciffc_wildfires_20251107.csv\"  # CSV or JSON supported\n",
    "\n",
    "OUT_DIR = \"outputs/logreg_fire_prob_20251002_1008\"\n",
    "\n",
    "# Time config\n",
    "SEQ_LEN          = 7\n",
    "DATA_START_DATE  = date(2025, 9, 12)   # index 0 in FWI/ECMWF series\n",
    "PRED_START_DATE  = date(2025, 10, 2)\n",
    "PRED_END_DATE    = date(2025, 10, 8)\n",
    "\n",
    "# Train on historical days only (avoid peeking into prediction horizon)\n",
    "TRAIN_END_DATE   = PRED_START_DATE - timedelta(days=1)\n",
    "\n",
    "# CIFFC fields (UPDATE TO MATCH YOUR FILE)\n",
    "CIFFC_DATE_FIELD = \"field_situation_report_date\"\n",
    "CIFFC_LAT_FIELD  = \"field_latitude\"\n",
    "CIFFC_LON_FIELD  = \"field_longitude\"\n",
    "CIFFC_CRS = \"EPSG:4326\"  # still lat/lon\n",
    "\n",
    "# Logistic regression sampling (to keep the dataset manageable)\n",
    "N_SAMPLES_TOTAL = 200_000\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Normalization constants used for features\n",
    "FWI_NORM_DENOM = 30.0          # typical FWI scaling for normalization\n",
    "DRYNESS_MIN_K = 5.0            # 5 K\n",
    "DRYNESS_RANGE_K = 15.0         # 5â€“20 K mapped into [0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "260a24e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stack_from_tifs(tif_paths):\n",
    "    \"\"\"Read list of GeoTIFFs into [T, C, H, W] (C is band count).\"\"\"\n",
    "    arrays = []\n",
    "    for path in tif_paths:\n",
    "        with rasterio.open(path) as src:\n",
    "            arr = src.read()  # [C, H, W]\n",
    "            arrays.append(arr)\n",
    "    return np.stack(arrays, axis=0)  # [T, C, H, W]\n",
    "\n",
    "\n",
    "def read_singleband_stack(tif_paths):\n",
    "    \"\"\"Read list of single-band GeoTIFFs into [T, H, W].\"\"\"\n",
    "    arrays = []\n",
    "    for path in tif_paths:\n",
    "        with rasterio.open(path) as src:\n",
    "            arr = src.read(1)  # [H, W]\n",
    "            arrays.append(arr)\n",
    "    return np.stack(arrays, axis=0)  # [T, H, W]\n",
    "\n",
    "\n",
    "def save_probability_map(prob_2d, ref_tif, out_path):\n",
    "    \"\"\"Save [H, W] float32 array in [0, 1] as GeoTIFF using ref_tif georeference.\"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    with rasterio.open(ref_tif) as src:\n",
    "        profile = src.profile.copy()\n",
    "    profile.update(\n",
    "        driver=\"GTiff\",\n",
    "        count=1,\n",
    "        dtype=\"float32\",\n",
    "        compress=\"lzw\",\n",
    "    )\n",
    "    with rasterio.open(out_path, \"w\", **profile) as dst:\n",
    "        dst.write(prob_2d.astype(\"float32\"), 1)\n",
    "\n",
    "\n",
    "def load_ciffc_by_day(path: str):\n",
    "    \"\"\"\n",
    "    Load CIFFC file (CSV or JSON) and return {date -> DataFrame(rows for that date)}.\n",
    "    - CSV: uses pandas.read_csv\n",
    "    - JSON: expects either {\"rows\": [...]} or a list of row dicts\n",
    "    \"\"\"\n",
    "    if path.lower().endswith(\".csv\"):\n",
    "        df = pd.read_csv(path)\n",
    "    else:\n",
    "        with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            data = json.load(f)\n",
    "        if isinstance(data, dict) and \"rows\" in data:\n",
    "            df = pd.DataFrame(data[\"rows\"])\n",
    "        elif isinstance(data, list):\n",
    "            df = pd.DataFrame(data)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported CIFFC JSON format. Expected dict with 'rows' or list of rows.\")\n",
    "\n",
    "    for col in [CIFFC_DATE_FIELD, CIFFC_LAT_FIELD, CIFFC_LON_FIELD]:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(\n",
    "                f\"Expected CIFFC field '{col}' not found. \"\n",
    "                f\"Available columns: {list(df.columns)}\"\n",
    "            )\n",
    "\n",
    "    df[\"ciffc_date\"] = pd.to_datetime(df[CIFFC_DATE_FIELD]).dt.date\n",
    "\n",
    "    grouped = {d: g.reset_index(drop=True) for d, g in df.groupby(\"ciffc_date\")}\n",
    "    return grouped\n",
    "\n",
    "\n",
    "def rasterize_ciffc_per_day(ciffc_by_day, date_list, ref_tif_path, ciffc_crs=CIFFC_CRS):\n",
    "    \"\"\"\n",
    "    Produce [N_days, H, W] CIFFC rasters aligned to FWI grid.\n",
    "    Cell = 1 if any fire record for that date falls in that cell, else 0.\n",
    "    \"\"\"\n",
    "    with rasterio.open(ref_tif_path) as src:\n",
    "        H = src.height\n",
    "        W = src.width\n",
    "        transform = src.transform\n",
    "        fwi_crs = src.crs\n",
    "\n",
    "    transformer = Transformer.from_crs(ciffc_crs, fwi_crs, always_xy=True)\n",
    "\n",
    "    out = np.zeros((len(date_list), H, W), dtype=np.float32)\n",
    "\n",
    "    for idx, d in enumerate(date_list):\n",
    "        if d not in ciffc_by_day:\n",
    "            continue\n",
    "\n",
    "        g = ciffc_by_day[d]\n",
    "        lons = g[CIFFC_LON_FIELD].values\n",
    "        lats = g[CIFFC_LAT_FIELD].values\n",
    "        if len(lons) == 0:\n",
    "            continue\n",
    "\n",
    "        xs, ys = transformer.transform(lons, lats)\n",
    "        for x, y in zip(xs, ys):\n",
    "            row, col = rowcol(transform, x, y)\n",
    "            if 0 <= row < H and 0 <= col < W:\n",
    "                out[idx, row, col] = 1.0\n",
    "\n",
    "    return out  # [N_days, H, W]\n",
    "\n",
    "\n",
    "def window_feature_maps(\n",
    "    fwi_window,     # [T, C_fwi, H, W]\n",
    "    d2m_window,     # [T, H, W]\n",
    "    t2m_window,     # [T, H, W]\n",
    "    ciffc_window,   # [T, H, W]\n",
    "    fwi_band_index=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute per-cell features from a T-day window:\n",
    "      - fwi_max_norm: max FWI over window, normalized by FWI_NORM_DENOM\n",
    "      - dryness_norm: max (T2m - Td2m) over window, mapped into [0,1]\n",
    "      - recent_fire:  1 if any fire in the lookback window, else 0\n",
    "    Returns three [H, W] float32 arrays.\n",
    "    \"\"\"\n",
    "    T, Cf, H, W = fwi_window.shape\n",
    "    assert fwi_band_index < Cf, \"FWI band index out of range.\"\n",
    "\n",
    "    # FWI max\n",
    "    fwi_band = fwi_window[:, fwi_band_index, :, :].astype(np.float32)\n",
    "    fwi_band = np.nan_to_num(fwi_band, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    fwi_max = np.max(fwi_band, axis=0)  # [H,W]\n",
    "    fwi_max_norm = np.clip(fwi_max / float(FWI_NORM_DENOM), 0.0, 5.0)  # cap extreme outliers\n",
    "\n",
    "    # Dryness max (T2m - Td2m)\n",
    "    dew_dep = (t2m_window - d2m_window).astype(np.float32)\n",
    "    dew_dep = np.nan_to_num(dew_dep, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    dew_dep_max = np.max(dew_dep, axis=0)\n",
    "    dryness_norm = (dew_dep_max - float(DRYNESS_MIN_K)) / float(DRYNESS_RANGE_K)\n",
    "    dryness_norm = np.clip(dryness_norm, 0.0, 1.0)\n",
    "\n",
    "    # Recent fire\n",
    "    recent_fire = (np.max(ciffc_window, axis=0) > 0).astype(np.float32)\n",
    "\n",
    "    return fwi_max_norm.astype(np.float32), dryness_norm.astype(np.float32), recent_fire.astype(np.float32)\n",
    "\n",
    "\n",
    "def fit_logistic_regression_from_samples(\n",
    "    fwi_paths, d2m_paths, t2m_paths, ciffc_daily, date_list,\n",
    "    train_end_date, seq_len=7, fwi_band_index=0,\n",
    "    n_samples_total=200_000, random_seed=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a sampled training dataset and fit sklearn LogisticRegression.\n",
    "\n",
    "    Label definition:\n",
    "      y_{t, i} = 1 if CIFFC indicates a fire in cell i on the target day t.\n",
    "\n",
    "    Features:\n",
    "      x_{t, i} derived from the seq_len-day lookback window ending at t.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_seed)\n",
    "\n",
    "    # determine training indices (must have a full window and be <= train_end_date)\n",
    "    idx_last = (train_end_date - DATA_START_DATE).days\n",
    "    idx_last = min(idx_last, len(date_list) - 1)\n",
    "    idx_first = seq_len - 1\n",
    "    train_indices = list(range(idx_first, idx_last + 1))\n",
    "    if not train_indices:\n",
    "        raise ValueError(\"No valid training days. Check TRAIN_END_DATE and DATA_START_DATE/SEQ_LEN.\")\n",
    "\n",
    "    n_days = len(train_indices)\n",
    "    per_day = max(1, n_samples_total // n_days)\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for idx_end in train_indices:\n",
    "        idx_start = idx_end - (seq_len - 1)\n",
    "\n",
    "        # read windows\n",
    "        fwi_window = read_stack_from_tifs(fwi_paths[idx_start:idx_end + 1])\n",
    "        d2m_window = read_singleband_stack(d2m_paths[idx_start:idx_end + 1])\n",
    "        t2m_window = read_singleband_stack(t2m_paths[idx_start:idx_end + 1])\n",
    "        ciffc_window = ciffc_daily[idx_start:idx_end + 1, :, :]\n",
    "\n",
    "        fwi_norm, dry_norm, recent_fire = window_feature_maps(\n",
    "            fwi_window, d2m_window, t2m_window, ciffc_window, fwi_band_index=fwi_band_index\n",
    "        )\n",
    "\n",
    "        # label is fire on the target day idx_end\n",
    "        y_map = ciffc_daily[idx_end, :, :].astype(np.int32)\n",
    "\n",
    "        fwi_flat = fwi_norm.ravel()\n",
    "        dry_flat = dry_norm.ravel()\n",
    "        fire_flat = recent_fire.ravel()\n",
    "        y_flat = y_map.ravel()\n",
    "\n",
    "        pos = np.flatnonzero(y_flat == 1)\n",
    "        neg = np.flatnonzero(y_flat == 0)\n",
    "\n",
    "        # Aim for ~50/50 per day when possible (class imbalance is severe otherwise)\n",
    "        n_pos_target = per_day // 2\n",
    "        n_pos = min(len(pos), n_pos_target)\n",
    "        n_neg = per_day - n_pos\n",
    "\n",
    "        if n_pos > 0:\n",
    "            pos_sel = rng.choice(pos, size=n_pos, replace=False)\n",
    "        else:\n",
    "            pos_sel = np.array([], dtype=np.int64)\n",
    "\n",
    "        # If there are not enough negatives (unlikely), sample with replacement\n",
    "        if len(neg) >= n_neg:\n",
    "            neg_sel = rng.choice(neg, size=n_neg, replace=False)\n",
    "        else:\n",
    "            neg_sel = rng.choice(neg, size=n_neg, replace=True)\n",
    "\n",
    "        sel = np.concatenate([pos_sel, neg_sel])\n",
    "        rng.shuffle(sel)\n",
    "\n",
    "        X = np.column_stack([fwi_flat[sel], dry_flat[sel], fire_flat[sel]]).astype(np.float32)\n",
    "        y = y_flat[sel].astype(np.int32)\n",
    "\n",
    "        X_list.append(X)\n",
    "        y_list.append(y)\n",
    "\n",
    "        d = date_list[idx_end]\n",
    "        print(f\"Training samples for {d}: pos={int(y.sum())}, neg={len(y)-int(y.sum())}\")\n",
    "\n",
    "    X_all = np.vstack(X_list)\n",
    "    y_all = np.concatenate(y_list)\n",
    "\n",
    "    print(f\"Total training samples: {len(y_all)} (pos={int(y_all.sum())}, neg={len(y_all)-int(y_all.sum())})\")\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=300,\n",
    "        class_weight=\"balanced\",\n",
    "    )\n",
    "    model.fit(X_all, y_all)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a0d21ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 FWI rasters.\n",
      "Found 29 d2m rasters and 29 t2m rasters.\n",
      "Loading CIFFC file: ciffc_wildfires_20251107.json\n",
      "CIFFC records for 250 unique dates.\n",
      "FWI channels: 1, grid size: H=2281, W=2709\n",
      "Training samples for 2025-09-18: pos=25, neg=14260\n",
      "Training samples for 2025-09-19: pos=13, neg=14272\n",
      "Training samples for 2025-09-20: pos=37, neg=14248\n",
      "Training samples for 2025-09-21: pos=20, neg=14265\n",
      "Training samples for 2025-09-22: pos=17, neg=14268\n",
      "Training samples for 2025-09-23: pos=20, neg=14265\n",
      "Training samples for 2025-09-24: pos=14, neg=14271\n",
      "Training samples for 2025-09-25: pos=16, neg=14269\n",
      "Training samples for 2025-09-26: pos=10, neg=14275\n",
      "Training samples for 2025-09-27: pos=21, neg=14264\n",
      "Training samples for 2025-09-28: pos=25, neg=14260\n",
      "Training samples for 2025-09-29: pos=22, neg=14263\n",
      "Training samples for 2025-09-30: pos=15, neg=14270\n",
      "Training samples for 2025-10-01: pos=23, neg=14262\n",
      "Total training samples: 199990 (pos=278, neg=199712)\n",
      "Fitted LogisticRegression coefficients:\n",
      "  intercept: [-7.50799329]\n",
      "  coef: [[-1.53309731  0.22797274 15.65468625]]\n"
     ]
    }
   ],
   "source": [
    "# 1) Locate input rasters\n",
    "fwi_paths = sorted(glob.glob(os.path.join(FWI_DIR, \"*.tif\")))\n",
    "if not fwi_paths:\n",
    "    raise RuntimeError(f\"No FWI tifs found in {FWI_DIR}\")\n",
    "num_days = len(fwi_paths)\n",
    "print(f\"Found {num_days} FWI rasters.\")\n",
    "\n",
    "d2m_paths = sorted(glob.glob(os.path.join(ECMWF_DIR, \"*d2m*.tif\")))\n",
    "t2m_paths = sorted(glob.glob(os.path.join(ECMWF_DIR, \"*t2m*.tif\")))\n",
    "if not d2m_paths:\n",
    "    raise RuntimeError(f\"No ECMWF d2m (dewpoint) tifs found in {ECMWF_DIR}\")\n",
    "if not t2m_paths:\n",
    "    raise RuntimeError(f\"No ECMWF t2m (temperature) tifs found in {ECMWF_DIR}\")\n",
    "if not (len(d2m_paths) == len(t2m_paths) == num_days):\n",
    "    raise RuntimeError(\n",
    "        f\"Mismatch in daily counts: FWI={num_days}, d2m={len(d2m_paths)}, t2m={len(t2m_paths)}. \"\n",
    "        \"They must match and be time-aligned.\"\n",
    "    )\n",
    "print(f\"Found {len(d2m_paths)} d2m rasters and {len(t2m_paths)} t2m rasters.\")\n",
    "\n",
    "# 2) Build date index\n",
    "date_list = [DATA_START_DATE + timedelta(days=i) for i in range(num_days)]\n",
    "\n",
    "# 3) Load CIFFC points and rasterize onto the FWI grid (daily)\n",
    "print(f\"Loading CIFFC file: {CIFFC_FILE}\")\n",
    "ciffc_by_day = load_ciffc_by_day(CIFFC_FILE)\n",
    "print(f\"CIFFC records for {len(ciffc_by_day)} unique dates.\")\n",
    "\n",
    "ciffc_daily = rasterize_ciffc_per_day(\n",
    "    ciffc_by_day=ciffc_by_day,\n",
    "    date_list=date_list,\n",
    "    ref_tif_path=fwi_paths[0],\n",
    ")\n",
    "\n",
    "# 4) Grid info\n",
    "with rasterio.open(fwi_paths[0]) as src:\n",
    "    C_fwi = src.count\n",
    "    H = src.height\n",
    "    W = src.width\n",
    "print(f\"FWI channels: {C_fwi}, grid size: H={H}, W={W}\")\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# 5) Fit logistic regression model from sampled training data\n",
    "logreg_model = fit_logistic_regression_from_samples(\n",
    "    fwi_paths=fwi_paths,\n",
    "    d2m_paths=d2m_paths,\n",
    "    t2m_paths=t2m_paths,\n",
    "    ciffc_daily=ciffc_daily,\n",
    "    date_list=date_list,\n",
    "    train_end_date=TRAIN_END_DATE,\n",
    "    seq_len=SEQ_LEN,\n",
    "    fwi_band_index=0,\n",
    "    n_samples_total=N_SAMPLES_TOTAL,\n",
    "    random_seed=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "print(\"Fitted LogisticRegression coefficients:\")\n",
    "print(\"  intercept:\", logreg_model.intercept_)\n",
    "print(\"  coef:\", logreg_model.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54fc6636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target dates: [datetime.date(2025, 10, 2), datetime.date(2025, 10, 3), datetime.date(2025, 10, 4), datetime.date(2025, 10, 5), datetime.date(2025, 10, 6), datetime.date(2025, 10, 7), datetime.date(2025, 10, 8)]\n",
      "2025-10-02: using window indices [14, 20]\n",
      "Saved outputs/logreg_fire_prob_20251002_1008/fire_prob_20251002.tif\n",
      "2025-10-03: using window indices [15, 21]\n",
      "Saved outputs/logreg_fire_prob_20251002_1008/fire_prob_20251003.tif\n",
      "2025-10-04: using window indices [16, 22]\n",
      "Saved outputs/logreg_fire_prob_20251002_1008/fire_prob_20251004.tif\n",
      "2025-10-05: using window indices [17, 23]\n",
      "Saved outputs/logreg_fire_prob_20251002_1008/fire_prob_20251005.tif\n",
      "2025-10-06: using window indices [18, 24]\n",
      "Saved outputs/logreg_fire_prob_20251002_1008/fire_prob_20251006.tif\n",
      "2025-10-07: using window indices [19, 25]\n",
      "Saved outputs/logreg_fire_prob_20251002_1008/fire_prob_20251007.tif\n",
      "2025-10-08: using window indices [20, 26]\n",
      "Saved outputs/logreg_fire_prob_20251002_1008/fire_prob_20251008.tif\n"
     ]
    }
   ],
   "source": [
    "# 6) Build target date list for predictions\n",
    "target_dates = []\n",
    "d = PRED_START_DATE\n",
    "while d <= PRED_END_DATE:\n",
    "    target_dates.append(d)\n",
    "    d += timedelta(days=1)\n",
    "\n",
    "print(\"Target dates:\", target_dates)\n",
    "\n",
    "# 7) Loop over target dates and generate probability maps\n",
    "chunk_size = 250_000  # prediction chunk size for memory control\n",
    "\n",
    "for target_date in target_dates:\n",
    "    idx_end = (target_date - DATA_START_DATE).days\n",
    "    idx_start = idx_end - (SEQ_LEN - 1)\n",
    "\n",
    "    if idx_start < 0 or idx_end >= num_days:\n",
    "        print(f\"Skipping {target_date}: window [{idx_start}, {idx_end}] out of range.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"{target_date}: using window indices [{idx_start}, {idx_end}]\")\n",
    "\n",
    "    # Read windows\n",
    "    fwi_window = read_stack_from_tifs(fwi_paths[idx_start:idx_end + 1])\n",
    "    d2m_window = read_singleband_stack(d2m_paths[idx_start:idx_end + 1])\n",
    "    t2m_window = read_singleband_stack(t2m_paths[idx_start:idx_end + 1])\n",
    "    ciffc_window = ciffc_daily[idx_start:idx_end + 1, :, :]\n",
    "\n",
    "    # Compute feature maps\n",
    "    fwi_norm, dry_norm, recent_fire = window_feature_maps(\n",
    "        fwi_window=fwi_window,\n",
    "        d2m_window=d2m_window,\n",
    "        t2m_window=t2m_window,\n",
    "        ciffc_window=ciffc_window,\n",
    "        fwi_band_index=0,\n",
    "    )\n",
    "\n",
    "    # Predict probabilities (chunked)\n",
    "    fwi_flat = fwi_norm.ravel()\n",
    "    dry_flat = dry_norm.ravel()\n",
    "    fire_flat = recent_fire.ravel()\n",
    "    n = fwi_flat.shape[0]\n",
    "\n",
    "    prob_flat = np.empty(n, dtype=np.float32)\n",
    "    for s in range(0, n, chunk_size):\n",
    "        e = min(n, s + chunk_size)\n",
    "        X_chunk = np.column_stack([fwi_flat[s:e], dry_flat[s:e], fire_flat[s:e]]).astype(np.float32)\n",
    "        prob_flat[s:e] = logreg_model.predict_proba(X_chunk)[:, 1].astype(np.float32)\n",
    "\n",
    "    prob = prob_flat.reshape((H, W))\n",
    "\n",
    "    # Save GeoTIFF aligned to FWI raster for target day\n",
    "    ref_tif = fwi_paths[idx_end]\n",
    "    out_name = f\"fire_prob_{target_date.strftime('%Y%m%d')}.tif\"\n",
    "    out_path = os.path.join(OUT_DIR, out_name)\n",
    "    save_probability_map(prob, ref_tif, out_path)\n",
    "\n",
    "    print(f\"Saved {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
